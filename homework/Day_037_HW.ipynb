{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業\n",
    "請閱讀以下相關文獻，並回答以下問題\n",
    "\n",
    "Linear Regression 詳細介紹\n",
    "\n",
    "Logistics Regression 詳細介紹\n",
    "\n",
    "1.線性回歸模型能夠準確預測非線性關係的資料集嗎?\n",
    "2.回歸模型是否對資料分布有基本假設?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.線性回歸模型能夠準確預測非線性關係的資料集嗎?\n",
    "Ans:可以.\n",
    "\n",
    "     simple linear regression 回歸可以定義為： Finding the curve that best fits your data is called regression, and when that curve is a straight line, it's called linear regression. \n",
    " \n",
    "     則polynomial regression(多項次回歸)則是以非線性關係的資料觀察其與依變量之間所呈現之線性關係.(說明獨立變量對依變量所造成的線性影響)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.回歸模型是否對資料分布有基本假設?\n",
    "Ans: 回估模型基本假設說明如下：\n",
    "    \n",
    "    回歸分析的五個基本假設：\n",
    "    \n",
    "1.线性性 & 可加性\n",
    "假设因变量为Y，自变量为X1，X2，则回归分析的默认假设为Y=b+a1X1+a2X2+ε。\n",
    "线性性：X1每变动一个单位，Y相应变动a1个单位，与X1的绝对数值大小无关。\n",
    "可加性：X1对Y的影响是独立于其他自变量（如X2）的。\n",
    "\n",
    "2.误差项（ε）之间应相互独立。\n",
    "若不满足这一特性，我们称模型具有自相关性（Autocorrelation）。\n",
    "\n",
    "3.自变量（X1，X2）之间应相互独立。\n",
    "若不满足这一特性，我们称模型具有多重共线性性（Multicollinearity）。\n",
    "\n",
    "4.误差项（ε）的方差应为常数。\n",
    "若满足这一特性，我们称模型具有同方差性（Homoskedasticity），若不满足，则为异方差性（Heteroskedasticity）。\n",
    "\n",
    "5.误差项（ε）应呈正态分布。\n",
    "\n",
    "\n",
    "\n",
    "資料來源：https://blog.csdn.net/Noob_daniel/article/details/76087829"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
